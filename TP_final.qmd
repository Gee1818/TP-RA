---
title: "Universidades"
subtitle: "TP Final - Regresion avanzada"
author: "Joaquin Bermejo, Franco Scarafia y Gerard Seward"
format: 
  html:
    df-print: paged
    code-fold: false
    theme: darkly
    toc: true
  pdf: default

#execute: 
  #echo: false
editor: visual
---

# Introduccion

Se nos presenta una base de datos sobre universidades publicas y privadas con las siguientes variables

| Variable       | Descripción                                                                                                                                                                                                                             |
|------------------------|-----------------------------------------------|
| `privada`      | indica si la universidad es privada o no.                                                                                                                                                                                               |
| `aplicaciones` | cantidad de aplicaciones recibidas por la universidad durante el último año (cada estudiante que aspira a ingresar debe presentar una aplicación formal, a partir de la cual es admitido/a o rechazado/a), medida en miles de personas. |
| `ingresantes`  | cantidad de aplicaciones aceptadas, medida en miles de personas.                                                                                                                                                                        |
| `estudiantes`  | cantidad total de estudiantes en carreras de grado, medida en miles de personas.                                                                                                                                                        |
| `top10`        | porcentaje de ingresantes que fueron parte del 10% de estudiantes con mejores calificaciones en sus respectivas escuelas secundarias.                                                                                                   |
| `cuota`        | costo de la cuota de la universidad, medida en miles de dólares.                                                                                                                                                                        |
| `prof_dr`      | porcentaje de profesores de la universidad que poseen título de doctorado.                                                                                                                                                              |
| `razon`        | tasa de estudiantes por profesor.                                                                                                                                                                                                       |
| `tasa_grad`    | porcentaje de estudiantes que se gradúan.                                                                                                                                                                                               |

La variable de interés es `tasa_grad` que indica el porcentaje de estudiantes que se gradúan

A continuacion se importan las librerias que utilizaremos y se lee la funte de la base de datos

```{r}
#| message: FALSE
library(tidyverse)
library(ggplot2)
library(MASS)
library(GGally)
library(caret)
library(corrplot)
library(janitor)
library(knitr)
library(leaps)
library(pROC)
library(glmnet)
```

```{r}
df = read.delim('1-data/universidades.txt')
df = df %>% 
  mutate(privada = ifelse(privada == "Si", TRUE, FALSE))

# categoricals_vars <- df %>%
#   select(where(is.factor)) %>%
#   names()

# continuous_vars <- df %>%
#   select(where(is.numeric)) %>%
#   names()
```

Estos son los primeros 5 registro para entender como estan representados los datos

```{r}
head(df)
```

# Resumen de los datos

```{r}
skimr::skim(df)
corrplot(cor(dplyr::select(df, -privada)),
         method = "color",
         type = "lower", 
         addCoef.col = "black",
         tl.cex = 0.6,
         tl.pos = "ld",
         tl.srt = 45,
         title = "Correlation Plot for Numerical Variables",
         order = "hclust",
         mar = c(0, 0, 2, 0))
#ggpairs(df)
#ggpairs(df, aes(colour = privada, alpha = 0.4))
```

Para la variable target `tasa_grad`, los coeficientes de pearson mas relevantes se dan para la siguientes variables,

1.  `cuota` con un valor positivo de 0.57
2.  `top10` con un valor positivo de 0.5
3.  `prof_dr` con un valor positivo de 0.31
4.  `razon` con un valor negativo de 0.31

## Privada

```{r}
ggplot(df, aes(x = privada, fill = privada))+
  geom_bar() + 
  labs(title = "Cantidad de alumnos por tipo de universidad",
       x = "Tipo",
       y = "Cant. alumnos")+
  theme_minimal()
```

```{r}
ggplot(df) +
  aes(x = tasa_grad) + 
  geom_histogram(na.rm = TRUE, bins = 12, color = "black", aes(fill = privada)) + 
  facet_wrap(~ privada) + 
  theme(legend.position = "bottom")+
  theme_minimal()
```

La variable `privada` es de tipo categórica con valores positivos (565) y negativos (212) cuya tasa de graduados se comporta diferente. Las universidades privadas tienden a tener una mayor tasa de graduados

## Cuota

```{r}
ggplot(df, aes(cuota))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de cuota",
       x = "Cuota")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = cuota, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "Cuota vs Tasa de graduados",
       x = "Cuota",
       y = "% de graduados")+
  theme_minimal()
```

La variable `cuota` es de tipo cuantitativa con las siguientes métricas estadísticas

| Variable   | Valor                         |
|------------|-------------------------------|
| Maximo     | `{r} round(max(df$cuota),2)`  |
| Promedio   | `{r} round(mean(df$cuota),2)` |
| Minimo     | `{r} round(min(df$cuota),2)`  |
| Desviacion | `{r} round(sd(df$cuota),2)`   |

Al graficar esta variable con el target notamos una relación lineal, aunque con mucha dispersión, donde para valores bajos de cuota hay una mayor variación entre el valor real con el un valor predicho con una regresión lineal donde `tasa_grad` \~ `cuota`

## Aplicaciones

```{r}
ggplot(df, aes(aplicaciones))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de aplicaciones",
       x = "aplicaciones")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = aplicaciones, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "aplicaciones vs Tasa de graduados",
       x = "aplicaciones",
       y = "% de graduados")+
  theme_minimal()
```

La variable `aplicaciones` es de tipo cuantitativa donde hay una concentración de observaciones grandes para valores bajos de aplicaciones.

No se observa una clara relación lineal contra `tasa_grad`

## Ingresantes

```{r}
ggplot(df, aes(ingresantes))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de ingresantes",
       x = "ingresantes")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = ingresantes, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "ingresantes vs Tasa de graduados",
       x = "ingresantes",
       y = "% de graduados")+
  theme_minimal()
```

La variable `ingresante` es de tipo cuantitativa donde hay una concentración de observaciones grandes para valores bajos de ingresantes.

No se observa una clara relación lineal contra `tasa_grad`

## Estudiantes

```{r}
ggplot(df, aes(estudiantes))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de estudiantes",
       x = "estudiantes")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = estudiantes, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "estudiantes vs Tasa de graduados",
       x = "estudiantes",
       y = "% de graduados")+
  theme_minimal()
```

La variable `estudiantes` es de tipo cuantitativa donde hay una concentracion de observaciones grandes para valores bajos de estudiantes.

No se observa una clara relacion lineal contra `tasa_grad`

## Top 10

```{r}
ggplot(df, aes(top10))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de top10",
       x = "top10")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = top10, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "top10 vs Tasa de graduados",
       x = "top10",
       y = "% de graduados")+
  theme_minimal()
```

La variable `top10` es de tipo cuantitativa con las siguientes metricas estadisticas

| Variable   | Valor                         |
|------------|-------------------------------|
| Maximo     | `{r} round(max(df$top10),2)`  |
| Promedio   | `{r} round(mean(df$top10),2)` |
| Minimo     | `{r} round(min(df$top10),2)`  |
| Desviacion | `{r} round(sd(df$top10),2)`   |

Al graficar esta variable con el target notamos una relación lineal entre ellas pero para valores bajos de porcentaje de top10 hay una mayor variación entre el valor real con el un valor predicho con una regresión lineal donde `tasa_grad` \~ `top10`

Otro aspecto de interés es que las regresiones para los dos valores de la variable `privada` tienen una pendiente similar, pero diferente intercepto

## Profesores con doctorado

```{r}
ggplot(df, aes(prof_dr))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de prof_dr",
       x = "prof_dr")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = prof_dr, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "prof_dr vs Tasa de graduados",
       x = "prof_dr",
       y = "% de graduados")+
  theme_minimal()
```

La variable `prof_dr` es de tipo cuantitativa con las siguientes métricas estadísticas

| Variable   | Valor                           |
|------------|---------------------------------|
| Maximo     | `{r} round(max(df$prof_dr),2)`  |
| Promedio   | `{r} round(mean(df$prof_dr),2)` |
| Minimo     | `{r} round(min(df$prof_dr),2)`  |
| Desviacion | `{r} round(sd(df$prof_dr),2)`   |

Al graficar esta variable con el target no se observa una clara relación lineal. Un aspecto de interés es que las regresiones para los dos valores de la variable `privada` tienen una pendiente similar, pero diferente intercepto

## Razon de alumnos por profesores

```{r}
ggplot(df, aes(razon))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de razon",
       x = "razon")+
  theme_minimal()+
  theme(legend.position = "none")
```

```{r}
ggplot(df, aes(x = razon, y = tasa_grad, color = privada)) +
  geom_point() + 
  geom_smooth(formula = "y ~ x", method = "lm", se = FALSE)+
  labs(title = "razon vs Tasa de graduados",
       x = "razon",
       y = "% de graduados")+
  theme_minimal()
```

La variable `razon` es de tipo cuantitativa con las siguientes métricas estadísticas

| Variable   | Valor                         |
|------------|-------------------------------|
| Maximo     | `{r} round(max(df$razon),2)`  |
| Promedio   | `{r} round(mean(df$razon),2)` |
| Minimo     | `{r} round(min(df$razon),2)`  |
| Desviacion | `{r} round(sd(df$razon),2)`   |

La variable estudiantes es de tipo cuantitativa donde hay una concentración de observaciones grandes para valores entre 10 y 15.

No se observa una clara relación lineal contra tasa_grad

## Tasa de graduados

```{r}
ggplot(df, aes(tasa_grad))+
  geom_histogram(bins = 30, aes(fill = "#F8766D", y = after_stat(density)))+
  geom_density(color = "blue")+
  labs(title = "Histograma de tasa_grad",
       x = "tasa_grad")+
  theme_minimal()+
  theme(legend.position = "none")
```

La variable `tasa_grad` es de tipo cuantitativa con las siguientes métricas estadísticas y es la variable target de nuestro análisis.

| Variable   | Valor                             |
|------------|-----------------------------------|
| Maximo     | `{r} round(max(df$tasa_grad),2)`  |
| Promedio   | `{r} round(mean(df$tasa_grad),2)` |
| Minimo     | `{r} round(min(df$tasa_grad),2)`  |
| Desviacion | `{r} round(sd(df$tasa_grad),2)`   |

# Regresión Lineal

## División en entrenamiento y prueba

```{r}
set.seed(1234)
filas_train <- sample(x = 1:nrow(df), size = nrow(df)*0.7) #asignacion aleatoria

df_train <- slice(df, filas_train)
df_test <- slice(df, -filas_train)
```

## Ajustes de modelos

El **primer modelo** propuesto surge de aplicar un método de selección *stepwise* considerando solamente las variables originales, sin interacciones.

```{r}
mod1 <- stepAIC(
  object = lm(tasa_grad ~ 1, data = df_train), #punto de partida
  scope = list(upper = lm(tasa_grad ~ ., data = df_train)), #máximo modelo posible
  direction = "both", #método de selección
  trace = FALSE, #para no imprimir resultados parciales
  k = 2, #penalización a emplear (2 = AIC, log(n) = BIC)
  steps = 1000 #máximo nro de pasos
)
mod1
```

El **segundo modelo** también surge de aplicar el método *stepwise* pero considerando como modelo maximal aquel con todas las interacciones de segundo orden.

```{r}
mod2 <- stepAIC(
  object = lm(tasa_grad ~ 1, data = df_train), #punto de partida
  scope = list(upper = lm(tasa_grad ~ .^2, data = df_train)), #máximo modelo posible
  direction = "both", #método de selección
  trace = FALSE, #para no imprimir resultados parciales
  k = 2, #penalización a emplear (2 = AIC, log(n) = BIC)
  steps = 1000 #máximo nro de pasos
)
mod2
```

El **tercer modelo** surge de aplicar la técnica de mejores subconjuntos. Visto que el modelo anterior incluye tres términos (dos efectos principales y una interacción entre ellos) se elige el mejor modelo con 3 variables explicativas.

```{r}
mejorsub <- regsubsets(x = tasa_grad ~ ., data = df_train)
summary(mejorsub)
```

```{r}
mod3 <- lm(tasa_grad ~ privada + cuota + top10, data = df_train)
```

## Comparación de modelos

```{r}
CME <- function(mod) { 
  SSE <- sum(mod$residuals^2)
  n <- length(mod$fitted.values)
  SSE / (n - 1) 
}
PRESS <- function(mod) {
  sum( ( mod$residuals / (1 - hatvalues(mod)) )^2 )
}
Cp <- function(mod) { 
  SSE <- sum(mod$residuals^2)
  mod_max <- lm(tasa_grad ~ .^2, data = df_train)
  SSE_max <- sum(mod_max$residuals^2) 
  n <- length(mod$fitted.values)
  p <- length(mod$coefficients)
  SSE / (SSE_max / (n - 1)) + 2*p - n
}

metricas <- data.frame(
  CME   = c( CME(mod1),   CME(mod2),   CME(mod3) ),
  PRESS = c( PRESS(mod1), PRESS(mod2), PRESS(mod3) ),
  Cp    = c( Cp(mod1),    Cp(mod2),    Cp(mod3) ),
  AIC   = c( AIC(mod1),   AIC(mod2),   AIC(mod3) ),
  BIC   = c( BIC(mod1),   BIC(mod2),   BIC(mod3) )
)
metricas
```

Puede verse que para casi todas las métricas, el mejor modelo (en términos de desempeño) es el segundo: aquel que considera dos explicativas y su interacción. Por lo tanto, el modelo seleccionado queda de la forma:

$$
\texttt{tasa_grad} = \beta_0 + \beta_1 \;\texttt{cuota} + \beta_2 \;\texttt{top10} + \beta_3 \;\texttt{cuota*top10} + \epsilon
$$

## Análisis de residuos

```{r}
sel_mod = mod2

diagnostico = broom::augment(sel_mod)
```

### Residuos versus valores ajustados

```{r}

ggplot(data = diagnostico) + 
    aes(x = .fitted, y = .resid) + 
    geom_point(alpha = 0.6) +
    geom_hline(aes(yintercept = 0, color = "red")) +
    xlab("Valores Ajustados") +
    ylab("Residuos") +
    theme_bw()+
    theme(legend.position = "none",
      axis.title = element_text(face = "bold"))
```

Se puede ver que la variancia de los residuos no es constante para todos los valores ajustados. En particular, se evidencia una mayor variabilidad para tasas de graduación predichas en el rango 55% a 65%.

La hipótesis anterior puede evaluarse mediante el test de Breusch-Pagan.

```{r}
lmtest::bptest(sel_mod)
```

Como el p-value resulta inferior al nivel de significación 5%, se rechaza la hipótesis nula, indicando que posiblemente no se esté cumpliendo el supuesto de homocedasticidad de los residuos.

### Residuos estandarizados

```{r}
diagnostico$id <- seq(1:nrow(diagnostico))

ggplot(data = diagnostico) +
  aes(x = id, y = .std.resid) + 
  geom_point(alpha = 0.6) +
  geom_hline(aes(yintercept = 0, color = "red")) +
  geom_hline(aes(yintercept = -3, color = "red")) +
  geom_hline(aes(yintercept = 3, color = "red")) +
  xlab("Observación") +
  ylab("Residuos estandarizados") +
  theme_bw() +
  theme(legend.position = "none",
        axis.title = element_text(face = "bold"))

```

Se encuentran 5 valores con residuos estandarizados mayores a 3 unidades, en valor absoluto. Esto corresponde a un `r round(100 * 5/nrow(df_train), 2)`% de la totalidad de las observaciones de entrenamiento.

### Residuos PRESS

```{r}
diagnostico$press <- qpcR::PRESS(sel_mod, verbose=FALSE)$residuals

ggplot(data = diagnostico) + 
  aes(x = id, y = press) + 
  geom_bar(stat="identity")+
  geom_hline(aes(yintercept = 0, color = "red")) +
  xlab("Observación") +
  ylab("PRESS") +
  theme_bw() +
  theme(legend.position = "none",
        axis.title = element_text(face = "bold"))
```

No se ve ninguna observación que arroje un residuo PRESS considerablemente mayor (en valor absoluto) al resto.

### Análisis de normalidad

```{r}
plot(sel_mod,2)

nortest::ad.test(sel_mod$residuals)
```

Dado que el p-value es inferior al nivel de significación del 5%, se rechaza la hipótesis nula de distribución Normal para los errores.

### Análisis de colinealidad

```{r}
car::vif(sel_mod)
```

Los términos `top10` y `cuota:top10` presentan un valor de VIF mayor a 5 unidades. Esto indicaría una colinealidad entre estos términos, lo cual resulta lógico dado que el segundo término refiere a la interacción entre el primer término y la variable explicativa restante. De hecho, puede verse que los valores de VIF para el modelo sin interacción se ven reducidos.

```{r}
car::vif(mod1)
```

## Interpretación de los predictores

```{r}
summary(sel_mod)
```

Los tres términos reusltan significativos al 5%. Por lo tanto, debido a la presencia de interacción, las interpretaciones de los coeficientes del modelo son las siguientes:

-   Aumentar mil dólares la cuota se asocia con un incremento promedio en la tasa de graduación igual a `2,33 - 0,015 * top10` unidades porcentuales.

-   Aumentar en una unidad porcentual el porcentaje de ingresantes que fueron parte del top 10% de estudiantes en sus escuelas secundarias se asocia con un incremento promedio en la tasa de graduación igual a `0,43 - 0,015 * top10` unidades porcentuales.

# Regularización y Predicción

## Ajuste con técnica Ridge

```{r}
set.seed(12343)

X_train = model.matrix(sel_mod)[,-1]
  
Y_train = df_train$tasa_grad

mod_ridge = train(
  x = X_train, y= Y_train,
  method = "glmnet",
  tuneGrid = expand.grid(alpha = 0, lambda = seq(0,1,by = 0.1)),
  metric = "RMSE",
  trControl = trainControl(method = "repeatedcv", number = 5, repeats = 5)
)

lambda_ridge = mod_ridge$bestTune[[2]]

mod_ridge_sel = glmnet(x = X_train, y = Y_train, alpha = 0, lambda = lambda_ridge)

lambda_ridge

```

## Ajuste con técnica Lasso

```{r}
set.seed(567)

mod_lasso = train(
  x = X_train, y= Y_train,
  method = "glmnet",
  tuneGrid = expand.grid(alpha = 1, lambda = seq(0,1,by = 0.1)),
  metric = "RMSE",
  trControl = trainControl(method = "repeatedcv", number = 5, repeats = 5)
)

lambda_lasso = mod_lasso$bestTune[[2]]

mod_lasso_sel = glmnet(x = X_train, y = Y_train, alpha = 1, lambda = lambda_lasso)

lambda_lasso
```

Para la técnica Lasso, el valor óptimo del parámetro de regulraización es \$\\lambda = 0\$, lo cual implica estimaciones equivalentes a Mínimos Cuadrados Ordinarios. En otras palabras, bajo la técnica Lasso se concluye que no sería necesario aplicar regularización.

## Comparación de modelos

### Ajuste

```{r}
coefs <- cbind(
  coefficients(sel_mod), 
  coefficients(mod_ridge_sel)
) %>% t()
rownames(coefs) <- c("MCO", "Ridge")
coefs
```

Los coeficientes asociados a los efectos principales se ven reducidos al aplicar regularización por Ridge.

### Capacidad predictiva

```{r}
pred_MCO = predict(sel_mod, newdata = df_test)

X_test = model.matrix(sel_mod, data = df_test)[,-1]
Y_test = df_test$tasa_grad

pred_ridge = predict(mod_ridge, newdata = X_test)

rmse_MCO = sqrt(mean((pred_MCO - Y_test)^2))
rmse_ridge = sqrt(mean((pred_ridge - Y_test)^2))

results = tibble(rmse_MCO, rmse_ridge)
results
```

Los valores de RMSE son muy similares para ambos métodos de estimación, aunque es menor para Mínimos Cuadrados Ordinarios, indicando que la regularización no mejora la capacidad predictiva del modelo.

# Regresión Logística

## Definición de variable respuesta (dicotómica)

```{r}
df <- df %>% mutate(tasa_grad_binaria = if_else(tasa_grad < 75, F, T))
```

## División en entrenamiento y prueba

```{r}
set.seed(1492)
particion_logreg <- createDataPartition(df$tasa_grad_binaria, p = 0.7, list = F)
logreg_train <- df[particion_logreg,]
logreg_test <- df[-particion_logreg,]
```

## Ajuste e interpretación del modelo

```{r}
logreg_mod <- glm(
  tasa_grad_binaria ~ privada + aplicaciones + ingresantes + estudiantes + top10 + cuota + prof_dr + razon, 
  family = binomial(link = "logit"), data = logreg_train
)
summary(logreg_mod)
```

```{r}
exp(logreg_mod$coefficients[c(3, 5:7)])
```

-   Ante un aumento de mil aplicaciones recibidas, la chance de que una universidad tenga una buena tasa de graduación aumenta en un 16%.
-   Ante un aumento de mil estudiantes en carreras de grado, la chance de que una universidad tenga una buena tasa de graduación disminuye en un 29%.
-   Ante un aumento en una unidad porcentual del porcentaje de ingresantes que fueron parte del top 10% de estudiantes en sus escuelas secundarias, la chance de que una universidad tenga una buena tasa se graduación aumenta en un 2%.
-   Ante un aumento de mil dólares en la cuota, la chance de que una universidad tenga una buena tasa de graduación aumenta en un 22%.

## Curva ROC y punto de corte óptimo

```{r}
curvaROC <- roc(
  response = logreg_train$tasa_grad_binaria,
  predictor = fitted.values(logreg_mod),
  quiet = TRUE
)
plot(curvaROC, print.auc = TRUE)
threshold <- pROC::coords(curvaROC, "best", ret = "threshold")[1,]
```

Se obtiene un valor de AUC (área bajo la curva) igual a 0,8, lo cual habla de un buen clasificador.

Bajo el método de Youden se obtiene un punto de corte óptimo igual a `r round(threshold, 3)`. Este valor es lejano al punto de corte por defecto: 0,5.

## Métricas de capacidad predictiva

```{r}
p_hat <- predict(logreg_mod, logreg_test)

observados <- logreg_test %>% 
  mutate(y = if_else(tasa_grad_binaria, "Buena tasa", "Mala tasa")) %>% 
  pull(y) %>% 
  factor(levels = c("Mala tasa", "Buena tasa"))

predichos <- factor(
  ifelse(p_hat >= threshold, "Buena tasa", "Mala tasa"), 
  levels = c("Mala tasa", "Buena tasa")
)
confusionMatrix(
  data = predichos, 
  reference = observados, 
  mode = "everything",
  positive = "Buena tasa"
)
```

-   **Precisión:** El modelo clasifica correctamente al 77% de las universidades del conjunto de prueba según si tienen o no una buena tasa de graduación.
-   **Sensibilidad:** Entre las universidades con buena tasa de graduación, sólo un 38% de ellas fueron clasificadas correctamente.
-   **Especificidad:** Entre las universidades con mala tasa de graduación, un 94% fueron clasificadas correctamente.
-   **VPP:** Cuando el modelo predice que una universidad tiene una buena tasa de graduación, acierta un 75% de las veces.
-   **VPN:** Cuando el modelo predice que una universidad tiene una mala tasa de graduación, acierta un 78% de las veces.
-   **F1:** La media armónica entre la sensibilidad y el VPP resulta igual a 50%.
-   **Kappa:** La capacidad predictiva del modelo propuesto es aceptable.
