---
title: "Universidades"
subtitle: "TP Final - Regresión Avanzada"
author: "Joaquin Bermejo, Franco Scarafia y Gerard Seward"
format: 
  html:
    df-print: paged
    code-fold: false
    theme: darkly
    toc: true
  pdf:
    echo: false
    warning: false
    message: false

#execute: 
  #echo: false
editor: visual
---

# Introducción

Se nos presenta una base de datos sobre universidades públicas y privadas con las siguientes variables

| Variable       | Descripción                                                                                                                                                                                                                             |
|---------------------------|---------------------------------------------|
| `privada`      | indica si la universidad es privada o no.                                                                                                                                                                                               |
| `aplicaciones` | cantidad de aplicaciones recibidas por la universidad durante el último año (cada estudiante que aspira a ingresar debe presentar una aplicación formal, a partir de la cual es admitido/a o rechazado/a), medida en miles de personas. |
| `ingresantes`  | cantidad de aplicaciones aceptadas, medida en miles de personas.                                                                                                                                                                        |
| `estudiantes`  | cantidad total de estudiantes en carreras de grado, medida en miles de personas.                                                                                                                                                        |
| `top10`        | porcentaje de ingresantes que fueron parte del 10% de estudiantes con mejores calificaciones en sus respectivas escuelas secundarias.                                                                                                   |
| `cuota`        | costo de la cuota de la universidad, medida en miles de dólares.                                                                                                                                                                        |
| `prof_dr`      | porcentaje de profesores de la universidad que poseen título de doctorado.                                                                                                                                                              |
| `razon`        | tasa de estudiantes por profesor.                                                                                                                                                                                                       |
| `tasa_grad`    | porcentaje de estudiantes que se gradúan.                                                                                                                                                                                               |

La variable de interés es `tasa_grad` que indica el porcentaje de estudiantes que se gradúan.

```{r}
#| message: FALSE
library(tidyverse)
library(ggplot2)
library(MASS)
library(GGally)
library(caret)
library(corrplot)
library(janitor)
library(knitr)
library(leaps)
library(pROC)
library(glmnet)
```

```{r}
df = read.delim('1-data/universidades.txt')
df = df %>% 
  mutate(privada = ifelse(privada == "Si", TRUE, FALSE))
```

# Regresión Lineal

## División en entrenamiento y prueba

```{r}
#| echo: true
set.seed(1234)
filas_train <- sample(x = 1:nrow(df), size = nrow(df)*0.7) #asignacion aleatoria

df_train <- slice(df, filas_train)
df_test <- slice(df, -filas_train)
```

## Ajustes de modelos

El **primer modelo** propuesto surge de aplicar un método de selección *stepwise* considerando solamente las variables originales, sin interacciones.

```{r}
mod1 <- stepAIC(
  object = lm(tasa_grad ~ 1, data = df_train), #punto de partida
  scope = list(upper = lm(tasa_grad ~ ., data = df_train)), #máximo modelo posible
  direction = "both", #método de selección
  trace = FALSE, #para no imprimir resultados parciales
  k = 2, #penalización a emplear (2 = AIC, log(n) = BIC)
  steps = 1000 #máximo nro de pasos
)
mod1
```

El **segundo modelo** también surge de aplicar el método *stepwise* pero considerando como modelo maximal aquel con todas las interacciones de segundo orden.

```{r}
mod2 <- stepAIC(
  object = lm(tasa_grad ~ 1, data = df_train), #punto de partida
  scope = list(upper = lm(tasa_grad ~ .^2, data = df_train)), #máximo modelo posible
  direction = "both", #método de selección
  trace = FALSE, #para no imprimir resultados parciales
  k = 2, #penalización a emplear (2 = AIC, log(n) = BIC)
  steps = 1000 #máximo nro de pasos
)
mod2
```

El **tercer modelo** surge de aplicar la técnica de mejores subconjuntos. Visto que el modelo anterior incluye tres términos (dos efectos principales y una interacción entre ellos) se elige el mejor modelo con 3 variables explicativas.

```{r}
mejorsub <- regsubsets(x = tasa_grad ~ ., data = df_train)
summary(mejorsub)
```

```{r}
mod3 <- lm(tasa_grad ~ privada + cuota + top10, data = df_train)
```

## Comparación de modelos

```{r}
CME <- function(mod) { 
  SSE <- sum(mod$residuals^2)
  n <- length(mod$fitted.values)
  SSE / (n - 1) 
}
PRESS <- function(mod) {
  sum( ( mod$residuals / (1 - hatvalues(mod)) )^2 )
}
Cp <- function(mod) { 
  SSE <- sum(mod$residuals^2)
  mod_max <- lm(tasa_grad ~ .^2, data = df_train)
  SSE_max <- sum(mod_max$residuals^2) 
  n <- length(mod$fitted.values)
  p <- length(mod$coefficients)
  SSE / (SSE_max / (n - 1)) + 2*p - n
}

metricas <- data.frame(
  CME   = c( CME(mod1),   CME(mod2),   CME(mod3) ),
  PRESS = c( PRESS(mod1), PRESS(mod2), PRESS(mod3) ),
  Cp    = c( Cp(mod1),    Cp(mod2),    Cp(mod3) ),
  AIC   = c( AIC(mod1),   AIC(mod2),   AIC(mod3) ),
  BIC   = c( BIC(mod1),   BIC(mod2),   BIC(mod3) )
)
metricas
```

Puede verse que para todas las métricas salvo BIC, el mejor modelo (en términos de desempeño) es el segundo: aquel que considera dos explicativas y su interacción. Por lo tanto, el modelo seleccionado queda de la forma:

$tasa\_grad = \beta_0 + \beta_1 \; cuota + \beta_2 \; top10 + \beta_3 \; cuota*top10 + \epsilon$

## Análisis de residuos

```{r}
sel_mod = mod2

diagnostico = broom::augment(sel_mod)
```

### Residuos versus valores ajustados

```{r}

ggplot(data = diagnostico) + 
    aes(x = .fitted, y = .resid) + 
    geom_point(alpha = 0.6) +
    geom_hline(aes(yintercept = 0, color = "red")) +
    xlab("Valores Ajustados") +
    ylab("Residuos") +
    theme_bw()+
    theme(legend.position = "none",
      axis.title = element_text(face = "bold"))
```

Se puede ver que la variancia de los residuos no es constante para todos los valores ajustados. En particular, se evidencia una mayor variabilidad para tasas de graduación predichas en el rango 55% a 65%.

La hipótesis anterior puede evaluarse mediante el test de Breusch-Pagan.

```{r}
lmtest::bptest(sel_mod)
```

Como el p-value resulta inferior al nivel de significación 5%, se rechaza la hipótesis nula, indicando que posiblemente no se esté cumpliendo el supuesto de homocedasticidad de los residuos.

### Residuos estandarizados

```{r}
diagnostico$id <- seq(1:nrow(diagnostico))

ggplot(data = diagnostico) +
  aes(x = id, y = .std.resid) + 
  geom_point(alpha = 0.6) +
  geom_hline(aes(yintercept = 0, color = "red")) +
  geom_hline(aes(yintercept = -3, color = "red")) +
  geom_hline(aes(yintercept = 3, color = "red")) +
  xlab("Observación") +
  ylab("Residuos estandarizados") +
  theme_bw() +
  theme(legend.position = "none",
        axis.title = element_text(face = "bold"))

```

Se encuentran 5 valores con residuos estandarizados mayores a 3 unidades, en valor absoluto. Esto corresponde a un `r round(100 * 5/nrow(df_train), 2)`% de la totalidad de las observaciones de entrenamiento.

### Residuos PRESS

```{r}
diagnostico$press <- qpcR::PRESS(sel_mod, verbose=FALSE)$residuals

ggplot(data = diagnostico) + 
  aes(x = id, y = press) + 
  geom_bar(stat="identity")+
  geom_hline(aes(yintercept = 0, color = "red")) +
  xlab("Observación") +
  ylab("PRESS") +
  theme_bw() +
  theme(legend.position = "none",
        axis.title = element_text(face = "bold"))
```

Se observa un mayor valor absoluto de los residuos PRESS para las observaciones que tenían errores estandarizados mayores a 3 unidades en el gráfico anterior.

### Análisis de normalidad

```{r}
plot(sel_mod,2)

nortest::ad.test(sel_mod$residuals)
```

Dado que el p-value es inferior al nivel de significación del 5%, se rechaza la hipótesis nula de distribución Normal para los errores.

### Análisis de colinealidad

```{r}
car::vif(sel_mod)
```

Los términos `top10` y `cuota:top10` presentan un valor de VIF mayor a 5 unidades. Esto indicaría una colinealidad entre estos términos, lo cual resulta lógico dado que el segundo término refiere a la interacción entre el primer término y la variable explicativa restante. De hecho, puede verse que los valores de VIF para el modelo sin interacción se ven reducidos.

```{r}
car::vif(mod1)
```

## Interpretación de los predictores

```{r}
summary(sel_mod)
```

Los tres términos reusltan significativos al 5%. Por lo tanto, debido a la presencia de interacción, las interpretaciones de los coeficientes del modelo son las siguientes:

-   Aumentar mil dólares la cuota se asocia con un incremento promedio en la tasa de graduación igual a `2,33 - 0,015 * top10` por la interacción en unidades porcentuales.

-   Aumentar en una unidad porcentual el porcentaje de ingresantes que fueron parte del top 10% de estudiantes en sus escuelas secundarias se asocia con un incremento promedio en la tasa de graduación igual a `0,43 - 0,015 * cuota` por la interacción en unidades porcentuales.

# Regularización y Predicción

## Ajuste con técnica Ridge

```{r}
set.seed(12343)

X_train = model.matrix(sel_mod)[,-1]
  
Y_train = df_train$tasa_grad

mod_ridge = train(
  x = X_train, y= Y_train,
  method = "glmnet",
  tuneGrid = expand.grid(alpha = 0, lambda = seq(0,1,by = 0.1)),
  metric = "RMSE",
  trControl = trainControl(method = "repeatedcv", number = 5, repeats = 5)
)

lambda_ridge = mod_ridge$bestTune[[2]]

mod_ridge_sel = glmnet(x = X_train, y = Y_train, alpha = 0, lambda = lambda_ridge)

print(paste("Mejor valor de lambda:", lambda_ridge))

```

## Ajuste con técnica Lasso

```{r}
set.seed(567)

mod_lasso = train(
  x = X_train, y= Y_train,
  method = "glmnet",
  tuneGrid = expand.grid(alpha = 1, lambda = seq(0,1,by = 0.1)),
  metric = "RMSE",
  trControl = trainControl(method = "repeatedcv", number = 5, repeats = 5)
)

lambda_lasso = mod_lasso$bestTune[[2]]

mod_lasso_sel = glmnet(x = X_train, y = Y_train, alpha = 1, lambda = lambda_lasso)

print(paste("Mejor valor de lambda:", lambda_lasso))
```

Para la técnica Lasso, el valor óptimo del parámetro de regularización es $\lambda = 0$, lo cual implica estimaciones equivalentes a Mínimos Cuadrados Ordinarios. En otras palabras, bajo la técnica Lasso se concluye que no sería necesario aplicar regularización.

## Comparación de modelos

### Ajuste

```{r}
coefs <- cbind(
  coefficients(sel_mod), 
  coefficients(mod_ridge_sel)
) %>% t()
rownames(coefs) <- c("MCO", "Ridge")
coefs
```

Los coeficientes asociados a los efectos principales se ven reducidos al aplicar regularización por Ridge.

### Capacidad predictiva

```{r}
pred_MCO = predict(sel_mod, newdata = df_test)

X_test = model.matrix(sel_mod, data = df_test)[,-1]
Y_test = df_test$tasa_grad

pred_ridge = predict(mod_ridge, newdata = X_test)

rmse_MCO = sqrt(mean((pred_MCO - Y_test)^2))
rmse_ridge = sqrt(mean((pred_ridge - Y_test)^2))

results = tibble(rmse_MCO, rmse_ridge)
results
```

Los valores de RMSE son muy similares para ambos métodos de estimación, aunque es menor para Mínimos Cuadrados Ordinarios, indicando que la regularización no mejora la capacidad predictiva del modelo.

# Regresión Logística

## Definición de variable respuesta (dicotómica)

```{r}
#| echo: true
df <- df %>% mutate(tasa_grad_binaria = if_else(tasa_grad < 75, F, T))
```

## División en entrenamiento y prueba

```{r}
#| echo: true
set.seed(1492)
particion_logreg <- createDataPartition(df$tasa_grad_binaria, p = 0.7, list = F)
logreg_train <- df[particion_logreg,]
logreg_test <- df[-particion_logreg,]
```

## Ajuste e interpretación del modelo

```{r}
logreg_mod <- glm(
  tasa_grad_binaria ~ privada + aplicaciones + ingresantes + estudiantes + top10 + cuota + prof_dr + razon, 
  family = binomial(link = "logit"), data = logreg_train
)
summary(logreg_mod)
```

```{r}
exp(logreg_mod$coefficients[c(3, 5:7)])
```

-   Ante un aumento de mil aplicaciones recibidas, la chance de que una universidad tenga una buena tasa de graduación aumenta en un 16%.
-   Ante un aumento de mil estudiantes en carreras de grado, la chance de que una universidad tenga una buena tasa de graduación disminuye en un 29%.
-   Ante un aumento en una unidad porcentual del porcentaje de ingresantes que fueron parte del top 10% de estudiantes en sus escuelas secundarias, la chance de que una universidad tenga una buena tasa se graduación aumenta en un 2%.
-   Ante un aumento de mil dólares en la cuota, la chance de que una universidad tenga una buena tasa de graduación aumenta en un 22%.

## Curva ROC y punto de corte óptimo

```{r}
curvaROC <- roc(
  response = logreg_train$tasa_grad_binaria,
  predictor = fitted.values(logreg_mod),
  quiet = TRUE
)
plot(curvaROC, print.auc = TRUE)
threshold <- pROC::coords(curvaROC, "best", ret = "threshold")[1,]
```

Se obtiene un valor de AUC (área bajo la curva) igual a 0,8, lo cual habla de un buen clasificador.

Bajo el método de Youden se obtiene un punto de corte óptimo igual a `r round(threshold, 3)`. Este valor es lejano al punto de corte por defecto: 0,5.

## Métricas de capacidad predictiva

```{r}
p_hat <- predict(logreg_mod, logreg_test)

observados <- logreg_test %>% 
  mutate(y = if_else(tasa_grad_binaria, "Buena tasa", "Mala tasa")) %>% 
  pull(y) %>% 
  factor(levels = c("Mala tasa", "Buena tasa"))

predichos <- factor(
  ifelse(p_hat >= threshold, "Buena tasa", "Mala tasa"), 
  levels = c("Mala tasa", "Buena tasa")
)
confusionMatrix(
  data = predichos, 
  reference = observados, 
  mode = "everything",
  positive = "Buena tasa"
)
```

-   **Precisión:** El modelo clasifica correctamente al 77% de las universidades del conjunto de prueba según si tienen o no una buena tasa de graduación.
-   **Sensibilidad:** Entre las universidades con buena tasa de graduación, sólo un 38% de ellas fueron clasificadas correctamente.
-   **Especificidad:** Entre las universidades con mala tasa de graduación, un 94% fueron clasificadas correctamente.
-   **VPP:** Cuando el modelo predice que una universidad tiene una buena tasa de graduación, acierta un 75% de las veces.
-   **VPN:** Cuando el modelo predice que una universidad tiene una mala tasa de graduación, acierta un 78% de las veces.
-   **F1:** La media armónica entre la sensibilidad y el VPP resulta igual a 50%.
-   **Kappa:** La capacidad predictiva del modelo propuesto es aceptable.
