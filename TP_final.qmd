---
title: "Universidades"
subtitle: "TP Final - Regresion avanzada"
author: "Joaquin Bermejo, Franco Scarafia y Gerard Seward"
format: 
  html:
    df-print: paged
    code-fold: true
    theme: darkly
    toc: true
  pdf: default

#execute: 
  #echo: false
editor: visual
---

## Introduccion

Se nos presenta una base de datos sobre universidades publicas y privadas con las siguientes variables

|Variable| Descripción
-------------------|------------------------------------------------------
|`privada`| indica si la universidad es privada o no.
|`aplicaciones`| cantidad de aplicaciones recibidas por la universidad durante el último año (cada estudiante que aspira a ingresar debe presentar una aplicación formal, a partir de la cual es admitido/a o rechazado/a), medida en miles de personas.
|`ingresantes`| cantidad de aplicaciones aceptadas, medida en miles de personas.
|`estudiantes`| cantidad total de estudiantes en carreras de grado, medida en miles de personas.
|`top10`| porcentaje de ingresantes que fueron parte del 10% de estudiantes con mejores calificaciones en sus respectivas escuelas secundarias.
|`cuota`| costo de la cuota de la universidad, medida en miles de dólares.
|`prof_dr`| porcentaje de profesores de la universidad que poseen título de doctorado.
|`razon`| tasa de estudiantes por profesor.
|`tasa_grad`| porcentaje de estudiantes que se gradúan.

La variable de interés es `tasa_grad` que indica el porcentaje de estudiantes que se gradúan

A continuacion se importan las librerias que utilizaremos y se lee la funte de la base de datos

```{r}
#| message: FALSE
library(tidyverse)
library(ggplot2)
library(GGally)
library(caret)
library(corrplot)
library(janitor)
library(knitr)
```

```{r}
df = read.delim('1-data/universidades.txt')
df = df %>% 
  mutate(privada = factor(privada))
head(df)
```

## Resumen de los datos

```{r}
skimr::skim(df)
corrplot(cor(df))
ggpairs(df)
```



Consigna I: Regresión Lineal
1. Dividir aleatoriamente al conjunto de datos en bloques de entrenamiento (70%) y prueba (30%), definiendo una semilla para hacer que el resultado sea reproducible. Salvo que se exprese lo contrario, todas las consignas presentadas a continuación deben responderse empleando el conjunto de datos de entrenamiento.

```{r}
set.seed(1234)
filas_train <- sample(x = 1:nrow(df), size = nrow(df)*0.7) #asignacion aleatoria

df_train <- slice(df, filas_train)
df_test <- slice(df, -filas_train)
```





2. Ajustar tres modelos diferentes de Regresión Lineal Múltiple con el método de los Mínimos Cuadrados Ordinarios (MCO), definiendo como variable respuesta a la tasa de graduación de cada universidad. Se debe justificar por qué se eligieron a esos tres modelos en particular (ejemplo: procesos automáticos, técnica del mejor subconjunto, criterios propios, etc.).





3. Comparar los 3 modelos a través de las siguientes métricas de performance: CME, PRESS, Cp , AIC y BIC. En base a los resultados observados, elegir un modelo “ganador”.






4. Realizar un análisis de residuos sobre el modelo seleccionado en el punto anterior. Este análisis debe incluir el chequeo de cumplimiento de supuestos, presencia de colinealidad y casos atípicos y/o influyentes.




5. Consierando el modelo elegido, interpretar en palabras del problema los efectos estimados de los predictores sobre la respuesta, incluida su significación estadística (resultados del test t).






Consigna II: Regularización y Predicción
1. Ajustar el modelo elegido en la etapa anterior mediante la técnica Ridge, eligiendo el parámetro de penalidad mediante validación cruzada k-fold. Informar el valor óptimo de λ y comparar el resultado de este ajuste con el obtenido mediante MCO.






2. Ajustar el modelo elegido en la etapa anterior mediante la técnica Lasso, eligiendo el parámetro de penalidad mediante validación cruzada k-fold. Informar el valor óptimo de λ y comparar el resultado de este ajuste con el obtenido mediante MCO.












3. Evaluar la capacidad predictiva de los modelos MCO, Ridge y Lasso utilizándolos para estimar la tasa de graduación de universidades presentes en el conjunto de datos de prueba. Proveer alguna medida del error de predicción y determinar cuál de los tres modelos es el más adecuado.













Consigna III: Regresión Logística
1. Sobre el conjunto de datos original, definir la variable respuesta:
(0 si tasa_gradi < 0.75)
(1 si tasa_gradi ≥ 0.75)





2. Dividir aleatoriamente al conjunto de datos inicial en bloques de entrenamiento (70%) y prueba (30%), definiendo una semilla para hacer que el resultado sea reproducible. Utilizar la función createDataPartition() del paquete caret para asegurarse que la proporción de éxitos en cada partición sea balanceada.






3. Ajustar un modelo de regresión logística para estudiar la variable binaria definida en el punto 1. Este modelo debe incluir todas las explicativas disponibles, a excepción de la variable tasa_grad original. En base al resultado obtenido, interpretar las razones de odds asociadas a predictores estadísticamente significativos al 5%.









4. Elegir el punto de corte óptimo para clasificación mediante el método de la curva ROC.







5. Utilizando el punto de corte hallado, clasificar las universidades del conjunto de datos de prueba y construir la matriz de confusión correspondiente. Informar e interpretar los valores observados de precisión, sensibilidad, especificidad, VPP, VPN, F1 y κ.
